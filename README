Capstone Project Summary
Matt Linderman
Business Problem Summary:
As a bank, maintaining customers is extremely important for a number of reasons.  Most namely, the deposits that customers maintain with our bank are critical in support of our ability to make loans to other customers.  Additionally, it can be incredibly expensive to have to attract new customers to backfill the exiting customers.
Because of this, it will be tremendously valuable to have insights into what customers are likely to attrite in advance of their exit to allow for proactive outreach and retention strategies.   Given the size of our customer base and the relatively small percentage of attrition, we must be able to do this in a data driven and targeted way to allow us to meaningfully reach out to a subset of customers that are at the greatest likelihood of attrition.
Problem Solving Approach:
For this project, we aimed to build a classifier model to predict customers that are likely to attrite the bank as an input into a proactive retention mechanism.   We attempted to do this using readily available transactional data for our existing customer base – as that data is available today and will always be readily available.   Additionally, we did this in a manner that removed any personally identifiable information reducing any concerns about data risk.
The data that we decided to use for this included basic transactional information such as:  average balances, direct deposit amounts, fees assessed, fees refunded, calls to the customer service line, etc.   We leveraged practices of basic data analysis and visualization to further assess the data, quality and potential imputed features (of which we created a number) based on business understanding.  As part of this analysis, it became clear that we needed to deal with an imbalance of classes (given the low % of records that were “closed” accounts) which we did as a data preparation step.
Additionally, we targeted 3 primary models that work well for classification problems – logistic regression, random forest and gradient boosting.  We first constructed a “baseline” model from which to compare all of these models.  As we built these models, we tested their initial performance and then applied tuning of hyperparameters to optimize each of the.
Outcomes and Next Steps:
Ultimately, we landed on gradient boosting as the optimal model for this classification resulting in strong performance and an accuracy rating of 97%+.   It is important to note that while this model performs well to identify customers likely to attrite, it does not uncover all of the underlying specific reasons of “why” they are attriting.  This will be a critical consideration in our next steps. 
In terms of next steps, we do plan to move this model forward into production at our bank.   We are also planning to work with our business partners to determine the business process that will be wrapped around this model.  This model will drive a proactive outreach to those customers likely to attrite.   As part of that process, the expectation is that the conversations with the customers will seek to uncover the specific reasons they are likely to attrite.  In the future, as we learn more of those, we will consider addition of new data (if available) into the model to help with both identification of the likelihood of attrition AND the reasons for that likely attrition.
**This overview is supported in detail within the Jupyter notebook in this repository.
Enter file contents here
